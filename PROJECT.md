# 项目介绍

林海漫游，一个专精软件工程和渗透攻击的AI Agent

# 项目TODOLIST

- [ ] 完成工具类
- [ ] 完成LLM对接部分
    - [x] 基本适配OpenAI
    - [ ] 编写测试
    - [ ] 支持打断Token生成
- [ ] 完成Agent逻辑

# 代码风格与规范

- 没有特殊情况，数据传递一般使用TypedDict
- 多个对象之间的交流一般使用Queue
- 每个模块都有对应的unit test测试其的功能

# 运行单元测试

使用以下命令激活venv并运行单元测试

```shell
. ./.secret.sh && . ./.venv/bin/activate && python -m linhai test
```

# Agent设计

## 架构设计

Agent具有以下功能

- 工具调用：调用各类MCP形式的工具
    - 为了减少Prompt长度，工具的文档保存均保存在单独的文件中
    - Agent在调用工具时，首先需要根据工具对应的文档条目名查询文档，获得工具的用法，然后调用工具
    - 为了完成工作，Agent会不可避免地需要操控用户的电脑，有些操作需要获得用户确认
- 历史总结：在上下文过长时压缩上下文
- 用户响应：分析用户的输入，并据此调整当前任务等信息
- 任务规划：在任务开始时规划TODOLIST，指定当前任务的最终目标和当前已经规划的任务
    - 对于渗透任务来说未来的小任务往往是未知的，在打进机器之前难以知道机器内部的信息
- 全局记忆：在单独的文件中保存用户的偏好等，Agent在运行时会动态修改这个全局记忆
    - 在开始时全局记忆只保存用户使用的语言（中文/英文/...）

## 工具调用

TODO

## 历史总结

Agent会在任务开始时或其他适当的时机总结当前的任务进程和任务信息，包括：

1. 主要目标：主要任务是什么，任务需要完成什么目标，达到什么效果
2. 关键概念：文档或其他信息源中提到的关键技术概念
    - 为了节省资源，这里仅总结该任务专有的信息
    - 如python基础等公开已知的、LLM已经学会的信息不在此列
    - 这些技术概念应该关键到没有这些信息Agent就没法良好地完成工作
3. 文件代码：关键且有用的各类文件和代码片段
4. 问题与解：Agent在执行任务时遇到的各类问题，如果有解法则提供解法
5. 待办任务：当前Agent规划好的，需要完成的各类任务，使用分级bullet point记录，`[ ]`和`[x]`标记未完成和已经完成
6. 当前任务：当前Agent正在处理的任务
7. 未来任务：列出未来可能需要完成的任务
8. 用户输入：用户提出的每一个要求，提供的每一个信息，**用户的每一条信息都很重要！**

总结应该尽量简洁

## 消息响应

Agent的运行过程为响应式，Agent需要通过Queue接受用户的消息和工具的运行结果

在主循环中，Agent应该根据当前任务自动运行，同时适时await用户和工具发来的消息

当获得用户消息时，Agent应：

1. 分析用户的消息，提取其中的关键信息
2. 如果需要的话，改写全局记忆和当前任务
3. 根据当前的信息调用工具

## 响应生成

Agent在调用LLM生成Token时，Token的生成可能会被Agent打断，此时Agent应该停止手中的工作，回到等待用户新消息的状态

## 状态转义

### 状态：等待用户

这是Agent的初始状态

#### 状态跳转


### 状态：自动运行

这是Agent调用工具解决问题的状态，Agent此时应该全自动地调用工具完成任务

#### 状态跳转

### 状态：暂停运行


## Agent的System Prompt设计

```markdown
# 情景

你是林海漫游，一个思维强大、擅长编程、记忆力强、措辞友好、小心谨慎的人工智能Agent

# 流程

## 处理用户输入

...

## 调用工具

...

# 注意

...
```

## Agent如何调用工具

为了减少Prompt长度，减少资源占用，同时为每个工具提供详尽的使用方法，工具的使用说明被外置在文档中

Agent在调用工具时，首先会查阅对应的文档，然后再调用工具

# 项目分层设计

## utils类

### exceptions.py

定义程序运行时的各类错误

### type_hints.py

定义其他函数使用的各种类型

### queue.py

基于asyncio.Queue的异步队列，定义各类和队列相关的操作

队列用来传输各种消息，设计类似于Golang中的chan，支持类似Golang中select的操作

支持一个select函数，这个select函数支持等到多个Queue，直到所有Queue关闭

select函数用来让Agent同时等待多个queue，Agent需要同时等待用户发来的消息、工具发来的消息等等，且用户可能会提前关闭Queue

### main.py

主函数，解析命令行参数，启动对应功能

其他地方没写好，暂时先添加调用unittest运行单元测试的功能

## LLM对接 llm.py

提供一个Procol LanguageModel, 用于让其他模块调用LLM

LanguageModel Protocol提供`answer_stream`函数，根据输入聊天历史流式生成LLM的回答

`answer_stream`函数返回一个`Answer`对象，其设计类似`requests`库中的`Response`类，用户可以遍历这个对象，获得当前LLM的回答的每个Token，在生成完毕后可以调用对应函数获得回答的全部文本和思考的文本

llm.py应该支持打断当前回答消息的生成

## Agent

TODO 文档未编写完毕

Agent为响应式的