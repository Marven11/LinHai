# 项目介绍

林海漫游，一个专精软件工程和渗透攻击的AI Agent

# 项目TODOLIST

- [x] 完成工具类（基础工具已实现）
- [x] 完成LLM对接部分
    - [x] 基本适配OpenAI
    - [x] 编写测试
    - [x] 支持打断Token生成
- [ ] 完成Agent逻辑
    - [x] 基本聊天
    - [x] 工具调用
        - [x] 弃用OpenAI的残废工具调用，使用markdown json code block的形式让Agent调用工具
        - [x] 添加基础工具（文件/命令/计算）
        - [ ] 实现lookup_tool_docs功能
        - [ ] agent调用工具需要获得用户确认
    - [x] 任务规划
    - [x] 用户响应
    - [x] 历史压缩
    - [x] 全局记忆管理

# 代码风格与规范

- 没有特殊情况，数据传递一般使用TypedDict
- 多个对象之间的交流使用asyncio.Queue
- 每个模块都应该有对应的unit test测试其的功能
- 没有特殊情况，每个新建的变量都要加上类型注释（type hint）
- 所有函数和方法都需要编写文档注释，写好输入输出的类型注释
- 没有特殊情况，不要使用`# `注释代码片段在干什么
- 类型检查器是必需的：类型检查器的输出可以极大帮助LLM修复漏洞
- 不要在语句结尾和空行处留下多余的空格
- 使用pylint和black自动找出代码风格问题

# LLM规范

如果你是辅助用户编写代码的机器人，你需要注意以下几点：

- 如果你遇到了什么问题，请询问用户
- 如果你思考了未来的任务，且任务不能一步完成，你应该在输出时提及你对未来的计划
    - 如：“当前我们遇到了...问题，未来应先...，然后...”
- 你应该注意上方的“代码风格与规范”，根据提及的代码风格编写代码

# Agent设计

## 架构设计

Agent具有以下功能

- 工具调用：调用各类的工具
    - Agent在调用工具时，首先需要根据工具对应的文档条目名查询文档，获得工具的用法，然后调用工具
    - 为了完成工作，Agent会不可避免地需要操控用户的电脑，有些操作需要获得用户确认
- 历史压缩：在上下文过长时压缩上下文
- 用户响应：用户可以随时打断agent输出，调整agent行为
- 任务规划：在任务开始时规划TODOLIST，指定当前任务的最终目标和当前已经规划的任务
    - 对于渗透任务来说未来的小任务往往是未知的，在打进机器之前难以知道机器内部的信息
- 全局记忆：在单独的文件中保存用户的偏好等，Agent在运行时会动态修改这个全局记忆
    - 在开始时全局记忆只保存用户使用的语言（中文/英文/...）

## 历史总结

Agent会在任务开始时或其他适当的时机总结当前的任务进程和任务信息，包括：

1. 主要目标：主要任务是什么，任务需要完成什么目标，达到什么效果
2. 关键概念：文档或其他信息源中提到的关键技术概念
    - 为了节省资源，这里仅总结该任务专有的信息
    - 如python基础等公开已知的、LLM已经学会的信息不在此列
    - 这些技术概念应该关键到没有这些信息Agent就没法良好地完成工作
3. 文件代码：关键且有用的各类文件和代码片段
4. 问题与解：Agent在执行任务时遇到的各类问题，如果有解法则提供解法
5. 待办任务：当前Agent规划好的，需要完成的各类任务，使用分级bullet point记录，`[ ]`和`[x]`标记未完成和已经完成
6. 当前任务：当前Agent正在处理的任务
7. 未来任务：列出未来可能需要完成的任务
8. 用户输入：用户提出的每一个要求，提供的每一个信息，**用户的每一条信息都很重要！**

总结应该尽量简洁

## 响应生成

Agent在调用LLM生成Token时，Token的生成可能会被Agent打断，此时Agent应该根据用户消息调整行为

## 状态转移

### 状态：等待用户

这是Agent的初始状态：等待用户的消息以进行下一步

当收到用户消息时执行“消息响应”流程

### 状态：自动运行

这是Agent调用工具解决问题的状态，Agent此时应该全自动地调用工具完成任务

Agent在发送工具调用消息，等待工具处理完成返回消息时处于此状态

当收到用户消息时，把用户的消息加入到当前消息中，然后产生回复。

### 状态：暂停运行

因其他原因暂停运行

当收到用户消息或者工具执行结果时执行“消息响应”流程

## 消息响应

Agent的运行过程为响应式，Agent需要通过asyncio.Queue接受用户的消息

在主循环中，Agent应该根据当前任务自动运行，适时等待用户的消息

## 工具调用

### 设计

Agent使用Markdown JSON代码块调用工具，格式如下：

```json
{"name": "tool_name", "arguments": {...}}
```

工具输出分为两种：
- 成功结果 (ToolResultMessage)
- 错误信息 (ToolErrorMessage)

除了计算器等常见的工具之外，还有一个特殊的工具`lookup_tool_docs`用于查询工具的使用文档。

`lookup_tool_docs`的输入是工具的名字，输出是对应工具的文档。这样我们就可以把工具的文档放在其他地方，降低prompt的长度

为了让OpenAI库不出错，禁止将role设置为tool

### 流式传输

Agent回答采用流式传输，工具调用在回答完成后解析

### 文档

> TODO: 这一个功能还没做

为了减少Prompt长度，减少资源占用，同时为每个工具提供详尽的使用方法，工具的使用说明被外置在文档中

Agent在调用工具时，首先会使用`lookup_tool_docs`查阅对应的文档，然后直接调用ToolManager的process_tool_call函数来执行工具

## 全局记忆

全局记忆保存在`LINHAI.md`中，采用markdown无序列表格式

Agent可动态修改，启动时附加到system prompt

## System Prompt设计

包含以下核心部分：
1. Agent基本描述
2. 行为准则
3. 工具调用规范
4. 全局记忆管理
5. 渗透测试授权检查

完整内容见prompt.py


# 消息设计

LLM的消息是根据系统文件等外部信息动态生成的，本项目的消息分为两种：

1. 在llm.py中定义的Message，用以表示更加多样的消息类型，如工具处理结果/错误信息，全局记忆消息等
2. 在type_hints.py中定义的LanguageModelMessage, 和OpenAI库的LLM消息类型兼容

生成LLM回复时，Message会被动态地转换为LanguageModelMessage，以实现动态修改System Prompt、全局记忆等内容
